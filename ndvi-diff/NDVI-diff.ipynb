{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDVI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import lithops\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import math\n",
    "import collections\n",
    "from rasterio.io import MemoryFile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "\n",
    "import cloudbutton_geospatial.s2froms3 as s2froms3\n",
    "from cloudbutton_geospatial.utils import notebook as notebook_utils\n",
    "from cloudbutton_geospatial.io_utils.ndvi import get_ndvi_params, ndvi_calculation, ndvi_tile_sentinel, get_subset_raster, lonlat_to_utm, get_poly_within\n",
    "from cloudbutton_geospatial.io_utils.plot import tiff_overview, plot_map\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros de input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos intervalos de fechas donde buscar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_from = datetime.date(year=2017, month=1, day=1)\n",
    "default_to = datetime.date(year=2017, month=6, day=1)\n",
    "\n",
    "from_date_before, to_date_before = notebook_utils.pick_date_range(default_from, default_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_from = datetime.date(year=2017, month=7, day=1)\n",
    "default_to = datetime.date(year=2017, month=12, day=1)\n",
    "\n",
    "from_date_after, to_date_after = notebook_utils.pick_date_range(default_from, default_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the tile's cloud percentage threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = notebook_utils.pick_percentage_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionemos la zona que analizaremos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the area which delimites the tiles you want to process (left click to mark a point in the map, right click to erase current selection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_region = notebook_utils.MapRegion(center=(37.119144346710314, -3.3297926678298877))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "lats = []\n",
    "lons = []\n",
    "points = []\n",
    "\n",
    "for value in map_region.get_region()[:-1]:\n",
    "    coords.append(value)\n",
    "    lats.append(value[1])\n",
    "    lons.append(value[0])\n",
    "\n",
    "start_date_before = from_date_before.value  # Start date to search images\n",
    "end_date_before = to_date_before.value  # End date to search images\n",
    "\n",
    "start_date_after = from_date_after.value  # Start date to search images\n",
    "end_date_after = to_date_after.value  # End date to search images\n",
    "\n",
    "what = ['B04', 'B08']  # What we want to download\n",
    "cc = percentage.value  # Minimum cloud cover on each image, 25 is 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def distance(origin, destination):\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
    "         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
    "         math.sin(dlon / 2) * math.sin(dlon / 2))\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "i, p = 0, 0\n",
    "\n",
    "while i != len(points):\n",
    "    p = i + 1\n",
    "    while p != len(points):\n",
    "        dis = distance(points[i], points[p])\n",
    "        divisions = int(dis / 100)\n",
    "        # If the zones are separated by more than 100 km, generate intermediate zones\n",
    "        if divisions > 0:\n",
    "            toSum = [(points[i][0] - points[p][0]) / (divisions + 1) , (points[i][1] - points[p][1]) / (divisions + 1)]\n",
    "            while divisions != 0:\n",
    "                point = points[i][0] - (toSum[0] * divisions)\n",
    "                # Not add duplicated lons/lats\n",
    "                if point not in lons:\n",
    "                    lons.append(points[i][0] - (toSum[0] * divisions))\n",
    "                    lats.append(points[i][1] - (toSum[1] * divisions))\n",
    "                divisions = divisions - 1\n",
    "        p = p + 1 \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscamos los registros de Sentinel 2 para analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenes_f1 = []\n",
    "scenes_f2 = []\n",
    "\n",
    "for longitude, latency in zip(lons, lats):\n",
    "    try:\n",
    "        # Get scenes from intital date\n",
    "        f1 = s2froms3.get_scene_list(lon=longitude, lat=latency, start_date=start_date_before, end_date=end_date_before,\n",
    "        what=what, cloud_cover_le=cc)\n",
    "\n",
    "        # Get scenes from end date\n",
    "        f2 = s2froms3.get_scene_list(lon=longitude, lat=latency, start_date=start_date_after, end_date=end_date_after,\n",
    "        what=what, cloud_cover_le=cc)\n",
    "\n",
    "        # Not add duplicated scenes\n",
    "        if len(scenes_f1) == 0 or f1 not in scenes_f1:\n",
    "            scenes_f1.append(f1)\n",
    "            scenes_f2.append(f2)\n",
    "\n",
    "            print(f'Found scenes {start_date}:', f1)\n",
    "            print(f'Found scenes {end_date}:', f2)\n",
    "            print(f'Lon: {longitude}, Lat: {latency}')\n",
    "            print(f'Cell: {f1[0][0].split(\"/\")[2]} {f1[0][0].split(\"/\")[3]} {f1[0][0].split(\"/\")[4]}\\n')\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "if len(scenes_f1) == 0:\n",
    "    raise Exception('No data found')\n",
    "\n",
    "scene = scenes_f1[-1][-1]\n",
    "scene_band = rasterio.open('s3://'+scene[0])\n",
    "windows = list(scene_band.block_windows())\n",
    "tile_band_keys = [tup[0][0] for tup in scenes_f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los cuadrantes que usamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_meta(key):\n",
    "    with rasterio.open('s3://'+key) as src:\n",
    "        x1, y1 = src.profile['transform'] * (0, 0)\n",
    "        x2, y2 = src.profile['transform'] * (src.profile['width'], src.profile['height'])\n",
    "    return key, (x1, y1), (x2, y2)\n",
    "\n",
    "fexec = lithops.FunctionExecutor(\n",
    "        backend='aws_lambda',\n",
    "        storage='aws_s3',\n",
    "        log_level='INFO',\n",
    "        runtime_memory=1024,\n",
    "        runtime='gfinol/nvdi-lithops:2.2'  # Runtime for AWS Lambda\n",
    ")\n",
    "\n",
    "fs_meta = fexec.map(get_tile_meta, tile_band_keys)\n",
    "tiles_meta = fexec.get_result(fs=fs_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyleaflet\n",
    "import ipywidgets\n",
    "import utm\n",
    "\n",
    "m = ipyleaflet.Map(center=(37.119144346710314, -3.3297926678298877), zoom=7.5)\n",
    "\n",
    "for tile_id, bound1, bound2 in tiles_meta:\n",
    "    x1, y1 = bound1\n",
    "    x2, y2 = bound2\n",
    "    xc, yc = (x1 + x2) / 2, y1\n",
    "    \n",
    "    wgs_bounds_1 = utm.to_latlon(x1, y1, 30, 'S')\n",
    "    wgs_bounds_2 = utm.to_latlon(x2, y2, 30, 'S')\n",
    "    # wgs_bounds_c = utm.to_latlon(xc, yc, 30, 'S')\n",
    "\n",
    "    rectangle = ipyleaflet.Rectangle(bounds=(wgs_bounds_1, wgs_bounds_2))\n",
    "    m.add_layer(rectangle)    \n",
    "\n",
    "m.layout.height=\"750px\"\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo del NDVI y de la diferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndvi(scene, ij_window, storage):\n",
    "    ij, window = ij_window\n",
    "    band_4_s3_loc, band_8_s3_loc = scene\n",
    "    band_path = band_4_s3_loc.split('/')\n",
    "    ndvi_local = f'/tmp/{band_path[7]}_{ij}_NDVI.tif'\n",
    "    jpg_local = f'/tmp/{band_path[7]}_{ij}_NDVI.jpg'\n",
    "\n",
    "    # generate nir and red objects as arrays in float64 format\n",
    "    band4 = rasterio.open('s3://'+band_4_s3_loc)  # red\n",
    "    band8 = rasterio.open('s3://'+band_8_s3_loc)  # nir\n",
    "\n",
    "    profile = band4.profile\n",
    "    profile.update(dtype='float64')\n",
    "    profile.update(width=window.width)\n",
    "    profile.update(height=window.height)\n",
    "\n",
    "    with rasterio.open(ndvi_local, 'w', **profile) as dst:\n",
    "        red = band4.read(1, window=window).astype('float64')\n",
    "        nir = band8.read(1, window=window).astype('float64')\n",
    "        ndvi = (np.where((nir + red) == 0., 0, (nir - red) / (nir + red))).astype('float64')\n",
    "        ndvi_mean = np.mean(ndvi, axis=0)\n",
    "        dst.write(ndvi, 1)\n",
    "        ndvi[0][0] = -1\n",
    "        ndvi[0][1] = 1\n",
    "        plt.imsave(jpg_local, ndvi, cmap=\"RdYlGn\")\n",
    "\n",
    "    with open(jpg_local, 'rb') as jpg_temp:\n",
    "        co_jpg = storage.put_cloudobject(jpg_temp.read(), key=jpg_local.replace('/tmp/', ''))\n",
    "\n",
    "    return ndvi_local, ndvi_mean, co_jpg\n",
    "\n",
    "\n",
    "def compute_ndvi_diff(old_scene, new_scene, ij_window, storage):\n",
    "    ij, window = ij_window\n",
    "    band_path = new_scene[0].split('/')\n",
    "    jpg_diff_local = f'/tmp/{band_path[7]}_{ij}_NDVI_DIFF.jpg'\n",
    "    key = old_scene[0].split('/')[7].rsplit('_', 3)[0]\n",
    "\n",
    "    ndvi_local_f1, ndvi_mean_f1, co_jpg_f1 = calculate_ndvi(old_scene, ij_window, storage)\n",
    "    ndvi_local_f2, ndvi_mean_f2, co_jpg_f2 = calculate_ndvi(new_scene, ij_window, storage)\n",
    "\n",
    "    ndvi_old = rasterio.open(ndvi_local_f1)\n",
    "    ndvi_new = rasterio.open(ndvi_local_f2)\n",
    "\n",
    "    profile = ndvi_old.profile\n",
    "    profile.update(dtype='float64')\n",
    "    profile.update(width=window.width)\n",
    "    profile.update(height=window.height)\n",
    "\n",
    "    no = ndvi_old.read(1).astype('float64')\n",
    "    nn = ndvi_new.read(1).astype('float64')\n",
    "    ndvi_cmp = ((nn - no) * (nn + no)).astype('float64')\n",
    "    ndvi_cmp[0][0] = -1\n",
    "    ndvi_cmp[0][1] = 1\n",
    "    plt.imsave(jpg_diff_local, ndvi_cmp, cmap=\"RdYlGn\")\n",
    "\n",
    "    with open(jpg_diff_local, 'rb') as jpg_diff_file:\n",
    "        co_jpg_diff = storage.put_cloudobject(jpg_diff_file, key=jpg_diff_local.replace('/tmp/', ''))\n",
    "\n",
    "    return key, ij_window, co_jpg_f1, co_jpg_f2, co_jpg_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the selected parameters, get the identifiers of the selected tiles from Sentinel-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterdata = []\n",
    "for scene_f1, scene_f2 in zip(scenes_f1, scenes_f2):\n",
    "    for wd in windows:\n",
    "        iterdata.append((scene_f1[0], scene_f2[0], wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fexec = lithops.FunctionExecutor(\n",
    "        backend='aws_lambda',\n",
    "        storage='aws_s3',\n",
    "        log_level='INFO',\n",
    "        runtime_memory=1024,\n",
    "        runtime='gfinol/nvdi-lithops:2.2'  # Runtime for AWS Lambda\n",
    ")\n",
    "\n",
    "fs = fexec.map(compute_ndvi_diff, iterdata)\n",
    "results = fexec.get_result(fs=fs)\n",
    "\n",
    "grouped_results = collections.defaultdict(list)\n",
    "\n",
    "for res in results:\n",
    "    key, ij_window, co_jpg_f1, co_jpg_f2, co_jpg_diff = res\n",
    "    grouped_results[key].append((ij_window, co_jpg_f1, co_jpg_f2, co_jpg_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando imagenes resultantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_jpg(data):\n",
    "    \n",
    "    file = '_'.join(data[0][1].key.split('_')[:5])\n",
    "    \n",
    "    if 'DIFF' in data[0][1].key:\n",
    "        out_file = f'{file}_NDVI_DIFF.jpg'\n",
    "    else:\n",
    "        out_file = f'{file}_NDVI.jpg'\n",
    "        \n",
    "    jpgs = {}\n",
    "\n",
    "    def get_window(data):\n",
    "        ij_window, co_jpg = data\n",
    "        row = ij_window[0][0]\n",
    "        col = ij_window[0][1]\n",
    "        jpg_stream = fexec.storage.get_cloudobject(co_jpg, stream=True)\n",
    "\n",
    "        if row not in jpgs:\n",
    "            jpgs[row] = [None]*11\n",
    "\n",
    "        jpgs[row][col] = Image.open(jpg_stream)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=16) as ex:\n",
    "        fs = list(ex.map(get_window, data))\n",
    "\n",
    "    new_im = Image.new('RGB', (scene_band.width, scene_band.height))\n",
    "\n",
    "    x_offset = 0\n",
    "    y_offset = 0\n",
    "\n",
    "    for row in sorted(jpgs.keys()):\n",
    "        for im in jpgs[row]:\n",
    "            new_im.paste(im, (x_offset, y_offset))\n",
    "            x_offset += im.size[0]\n",
    "        x_offset = 0\n",
    "        y_offset += im.size[1]\n",
    "        \n",
    "    thumbnail_zise = (640, 640)\n",
    "    new_im.thumbnail(thumbnail_zise)\n",
    "\n",
    "    return (out_file, new_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import ScalarMappable \n",
    "f, ax = plt.subplots(1, 3, figsize=(18, 18))\n",
    "\n",
    "\n",
    "key_to_plot = 'S2A_30SVG'\n",
    "\n",
    "co_jpgs_f1 = [(res[0], res[1]) for res in grouped_results[key_to_plot]]\n",
    "co_jpgs_f2 = [(res[0], res[2]) for res in grouped_results[key_to_plot]]\n",
    "co_jpgs_diff = [(res[0], res[3]) for res in grouped_results[key_to_plot]]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as ex:\n",
    "    images = dict(ex.map(get_jpg, [co_jpgs_f1, co_jpgs_f2, co_jpgs_diff]))\n",
    "\n",
    "for i, image_key in enumerate(sorted(images.keys())):\n",
    "    ax[i].set_title(image_key)\n",
    "    ax[i].imshow(images[image_key])\n",
    "\n",
    "#plt.colorbar(ScalarMappable(cmap='RdYlGn'), fraction=0.046, pad=0.04)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
